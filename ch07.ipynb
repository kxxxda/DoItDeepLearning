{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## 07-1 다중 분류 신경망을 만듭니다"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "class MultiClassNetwork:\r\n",
    "\r\n",
    "    def __init__(self, units = 10, batch_size = 32, learning_rate = 0.1, l1 = 0, l2 = 0):\r\n",
    "        self.units = units  # 은닉층의 뉴런 개수\r\n",
    "        self.batch_size = batch_size  # 배치 크기\r\n",
    "        self.w1 = None  # 은닉층의 가중치\r\n",
    "        self.b1 = None  # 은닉층의 절편\r\n",
    "        self.w2 = None  # 출력층의 가중치\r\n",
    "        self.b2 = None  # 출력층의 절편\r\n",
    "        self.a1 = None  # 은닉층의 활성화 출력\r\n",
    "        self.losses = []  # 훈련 손실\r\n",
    "        self.val_losses = []  # 검증 손실\r\n",
    "        self.lr = learning_rate  # 학습률\r\n",
    "        self.l1 = l1  # L1 손실 하이퍼파라미터\r\n",
    "        self.l2 = l2  # L2 손실 하이퍼파라미터\r\n",
    "\r\n",
    "    def forpass(self, x):\r\n",
    "        z1 = np.dot(x, self.w1) + self.b1  # 첫 번째 층의 선형 식 계산\r\n",
    "        self.a1 = self.sigmoid(z1)  # 활성화 함수 , 시그모이드 적용 !\r\n",
    "        z2 = np.dot(self.a1, self.w2) + self.b2  # 두 번째 츠으이 선형 식 계산\r\n",
    "\r\n",
    "    def backprop(self, x, err):\r\n",
    "        m = len(x)  # 샘플 개수\r\n",
    "        # 출력층의 가중치와 절편에 대한 그래디언트를 계산\r\n",
    "        w2_grad = np.dot(self.a1.T, err) / m\r\n",
    "        b2_grad = np.sum(err) / m\r\n",
    "        # 시그모이드 함수까지 그래디언트를 계산\r\n",
    "        err_to_hidden = np.dot(err, self.w2.T) * self.a1 * (1 - self.a1)\r\n",
    "        # 은닉층의 가중치와 절편에 대한 그래디언트를 계산\r\n",
    "        w1_grad = np.dot(x.T, err_to_hidden) / m\r\n",
    "        b1_grad = np.sum(err_to_hidden, axis = 0) / m\r\n",
    "        return w1_grad, b1_grad, w2_grad, b2_grad\r\n",
    "\r\n",
    "    def sigmoid(self, z):\r\n",
    "        z = np.clip(z, -100, None)  # 안전한 계산위해 클리핑 \r\n",
    "        a = 1 / (1 + np.exp(-z))\r\n",
    "        return a\r\n",
    "\r\n",
    "    def softmax(self, z):\r\n",
    "        z = np.clip(z, -100, None)  # 안전한 np.exp() 계산 위해 클리핑\r\n",
    "        exp_z = np.exp(z)\r\n",
    "        return exp_z / np.sum(exp_z, axis = 1).reshape(-1, 1)\r\n",
    "\r\n",
    "    def init_weights(self, n_features, n_classes):\r\n",
    "        self.w1 = np.random.normal(0, 1, (n_features, self.units))  # (특성 개수, 은닉층의 크기)\r\n",
    "        self.b1 = np.zeros(self.units)  # 은닉층의 크기\r\n",
    "        self.w2 = np.random.normal(0, 1, (self.units, n_classes))  # (은닉층의 크기, 클래스 개수)\r\n",
    "        self.b2 = np.zeros(n_classes)\r\n",
    "\r\n",
    "    def fit(self, x, y, epochs = 100, x_val = None, y_val = None):\r\n",
    "        np.random.seed(42)\r\n",
    "        self.init_weights(x.shape[1], y.shape[1])\r\n",
    "        for i in range(epochs):\r\n",
    "            loss = 0\r\n",
    "            print('.', end='')\r\n",
    "            # 제너레이터 함수에서 반환한 미니배치를 순환한다.\r\n",
    "            for x_batch, y_batch in self.gen_batch(x, y):\r\n",
    "                a = self.training(x_batch, y_batch)\r\n",
    "                # 안전한 계산 위해 클리핑\r\n",
    "                a = np.clip(a, 1e-10, 1-1e-10)\r\n",
    "                # 로그 손실과 규제 손실을 더해서 리스트에 추가\r\n",
    "                loss += np.sum(-y_batch*np.log(a))\r\n",
    "            self.losses.append((loss + self.reg_loss()) / len(X))\r\n",
    "            # 검증 세트에 대한 손실을 계산한다.\r\n",
    "            self.update_val_loss(x_val, y_val)\r\n",
    "\r\n",
    "        def gen_batch(self, x, y):\r\n",
    "            length = len(x)\r\n",
    "            bins = length // self.batch_size\r\n",
    "            if length % self.batch_size:\r\n",
    "                bins += 1  # 나누어 떨어지지 않을 때\r\n",
    "            indexes = np.random.permutation(np.arange(len(x))) # 인덱스를 섞습니다.\r\n",
    "            x = x[indexes]\r\n",
    "            y = y[indexes]\r\n",
    "            for i in range(bins):\r\n",
    "                start = self.batch_size * i\r\n",
    "                end = self.batch_size * (i + 1)\r\n",
    "                yield x[start:end], y[start:end]  # 배치 사이즈만큼 슬라이싱해서 반환\r\n",
    "\r\n",
    "        def training(self, x, y):\r\n",
    "            m = len(x)  # 샘플 개수를 저장\r\n",
    "            z = self.forpass(x)\r\n",
    "            a = self.softmax(z)\r\n",
    "            err = -(y - a)\r\n",
    "            # 오차를 역전파해서 그래디언트를 계산\r\n",
    "            w1_grad, b1_grad, w2_grad, b2_grad = self.backprop(x, err)\r\n",
    "            # 그래디언트에서 페널티 항의 미분 값을 뺀다.\r\n",
    "            w1_grad += (self.l1 * np.sign(self.w1) + self.l2 * self.w1) / m\r\n",
    "            w2_grad += (self.l1 * np.sign(self.w2) + self.l2 * self.w2) / m\r\n",
    "            # 은닉층의 가중치와 절편을 업데이트합니다.\r\n",
    "            self.w1 -= self.lr * w1_grad\r\n",
    "            self.b1 -= self.lr * b1_grad\r\n",
    "            # 출력층의 가중치와 절편을 업데이트합니다.\r\n",
    "            self.w2 -= self.lr * w2_grad\r\n",
    "            self.b2 -= self.lr * b2_grad\r\n",
    "            return a\r\n",
    "\r\n",
    "        def predict(self, x):\r\n",
    "            z = self.forpass(x)\r\n",
    "            return np.argmax(z, axis = 1)  # 가장 큰 값의 인덱스를 반환\r\n",
    "\r\n",
    "        def score(self, x, y):\r\n",
    "            # 예측과 타깃 열벡터를 비교해서 True의 비율을 반환\r\n",
    "            return np.mean(self.predict(x) == np.argmax(y, axis = 1))\r\n",
    "\r\n",
    "        def reg_loss(self):\r\n",
    "            # 은닉층과 출력층의 가중치에 규제를 적용합니다.\r\n",
    "            return self.l1 * (np.sum(np.abs(self.w1)) + np.sum(np.abs(self.w2))) + \\\r\n",
    "                self.l2 / 2 * (np.sum(self.w1**2) + np.sum(self.w2**2))\r\n",
    "\r\n",
    "        def update_val_loss(self, x_val, y_val):\r\n",
    "            z = self.forpass(x_val)\r\n",
    "            a = self.softmax(z)\r\n",
    "            a = np.clip(a, 1e-10, 1-1e-10)\r\n",
    "            # 크로스 엔트로피 손실과 규제 손실을 더해서 리스트에 추가\r\n",
    "            val_loss = np.sum(-y_val*np.log(a))\r\n",
    "            self.val_losses.append((val_loss + self.reg_loss()) / len(y_val))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 의류 이미지를 분류해 보자"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "import tensorflow as tf"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "tf.__version__\r\n",
    "\r\n",
    "# 버전 확인하기"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'2.6.0'"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "(x_train_all, y_train_all), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# 훈련 세트의 크기 확인하기\r\n",
    "print(x_train_all.shape, y_train_all.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(60000, 28, 28) (60000,)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "# 샘플 이미지 확인하기\r\n",
    "plt.imshow(x_train_all[0], cmap = \"gray\")\r\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "# 타깃의 내용과 의미 확인하기\r\n",
    "\r\n",
    "print(y_train_all[:10])\r\n",
    "\r\n",
    "# y_train_all 의 크기는 60000개의 요소를 가진 1차원 배열이다.\r\n",
    "# 이 배열에는 0~9까지의 정수로 이루어진 클래스 레이블이 들어있다."
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[9 0 0 3 0 2 7 2 5 5]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "class_names = ['티셔츠/윗도리', '바지', '스웨터', '드레스', '코트', '샌들', '셔츠', '스니커즈', '가방', '앵클부츠']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "# 각 레이블(0~9)의 의미를 알아보자\r\n",
    "\r\n",
    "print(class_names[y_train_all[0]])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "앵클부츠\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "# 흔련 데이터 세트를 훈련 세트와 검증 세트로 나누기 전에 훈련 세트의 타깃값들이 고르게 분포되어 있는지 알아보자\r\n",
    "\r\n",
    "np.bincount(y_train_all)\r\n",
    "\r\n",
    "# 각 레이블당 6000개의 데이터가 들어있다."
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000],\n",
       "      dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "from sklearn.model_selection import train_test_split"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "# 훈련세트와 검증세트로 나누기\r\n",
    "\r\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train_all, y_train_all, stratify = y_train_all, test_size = 0.2, random_state = 42)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "# 잘 나눠졌는지 확인\r\n",
    "\r\n",
    "np.bincount(y_train)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([4800, 4800, 4800, 4800, 4800, 4800, 4800, 4800, 4800, 4800],\n",
       "      dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "np.bincount(y_val)\r\n",
    "\r\n",
    "# 데이터 세트를 나눈 뒤, 클래스의 균형이 맞는지 확인하는 것이 좋다."
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200],\n",
       "      dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "# 이전에는 평균 0, 분산이 1이 되도록 정규화를 해줬는데 이미지 데이터이기 때문에\r\n",
    "# 이미지 데이터는 픽셀마다 0~255 사이의값을 가지기 때문에 이 값을 255로 나눠서 0~1 값이 되도록 맞춰준다.\r\n",
    "\r\n",
    "x_train = x_train / 255\r\n",
    "x_val = x_val / 255"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "# MultiClassNetwork는 1차원 배열의 샘플을 기대하기 때문에\r\n",
    "# 훈련 세트와 검증 세트의 차원을 바꿔준다.\r\n",
    "\r\n",
    "x_train = x_train.reshape(-1, 784)\r\n",
    "x_val = x_val.reshape(-1, 784)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "print(x_train.shape, x_val.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(48000, 784) (12000, 784)\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit"
  },
  "interpreter": {
   "hash": "0611604c638db2c10c53cd7ac769fdce0e5d7f70f7d9206f4956bee3c7157847"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}